{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import binom\n",
    "import pandas as pd\n",
    "\n",
    "def initialize_random_params(k):\n",
    "    params = {'phi': np.random.uniform(0, 1, size=k),\n",
    "              'p': np.random.uniform(0, 1, size=k)}\n",
    "    return params\n",
    "\n",
    "def e_step(x, params):\n",
    "    k = len(params['phi'])\n",
    "    log_p_y_x = np.zeros((x.shape[0], k))\n",
    "    for i in range(k):\n",
    "        log_p_y_x[:, i] = np.log(params['phi'][i]) + np.sum(binom.logpmf(x, n=1, p=params['p'][i]), axis=1)\n",
    "    log_p_y_x_norm = logsumexp(log_p_y_x, axis=1)\n",
    "    p_y_x = np.exp(log_p_y_x - log_p_y_x_norm[:, np.newaxis])\n",
    "    return log_p_y_x_norm, p_y_x\n",
    "\n",
    "def m_step(x, params):\n",
    "    k = len(params['phi'])\n",
    "    n = x.shape[0]\n",
    "    _, p_y_x = e_step(x, params)\n",
    "    phi = np.sum(p_y_x, axis=0) / n\n",
    "    p = np.mean([np.sum(p_y_x[:, i, np.newaxis] * x, axis=0) / np.sum(p_y_x[:, i]) for i in range(k)], axis=1)\n",
    "\n",
    "    return {'phi': phi, 'p': p}\n",
    "\n",
    "def get_avg_log_likelihood(x, params):\n",
    "    loglikelihood, _ = e_step(x, params)\n",
    "    return np.mean(loglikelihood)\n",
    "\n",
    "def run_em(x, params):\n",
    "    avg_loglikelihoods = []\n",
    "    while True:\n",
    "        avg_loglikelihood = get_avg_log_likelihood(x, params)\n",
    "        avg_loglikelihoods.append(avg_loglikelihood)\n",
    "        if len(avg_loglikelihoods) > 1 and abs(avg_loglikelihoods[-1] - avg_loglikelihoods[-2]) < 0.00001:\n",
    "            break\n",
    "        params = m_step(x, params)\n",
    "    \n",
    "    print(\"EM algorithm converged.\")\n",
    "    print(\"Final Parameters:\")\n",
    "    print(f\"\\tphi: {params['phi']}\")\n",
    "    print(f\"\\tp: {params['p']}\")\n",
    "\n",
    "    _, posterior = e_step(x, params)\n",
    "    forecasts = np.argmax(posterior, axis=1)\n",
    "    return forecasts, posterior, avg_loglikelihoods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the path to your text file\n",
    "file_path = \"https://www.ccs.neu.edu/home/vip/teach/DMcourse/2_cluster_EM_mixt/HW2/coin_flips_outcome.txt\"\n",
    "\n",
    "# Read the data into a dataframe\n",
    "df = pd.read_csv(file_path, sep=\" \", header=None)\n",
    "x = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Parameter For binomial: \n",
      "EM algorithm converged.\n",
      "Final Parameters:\n",
      "\tphi: [0.3058543  0.51552678 0.17861892]\n",
      "\tp: [0.23640626 0.60961574 0.9317092 ]\n",
      "total steps:  53\n"
     ]
    }
   ],
   "source": [
    "# Unsupervised learning\n",
    "print(\"Learned Parameter For binomial: \")\n",
    "random_params = initialize_random_params(3)\n",
    "unsupervised_forecasts, unsupervised_posterior, unsupervised_loglikelihoods = run_em(x, random_params)\n",
    "print(\"total steps: \", len(unsupervised_loglikelihoods))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
