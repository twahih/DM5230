{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import time\n",
    "\n",
    "# Function to download file from URL\n",
    "def download_file(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def read_transactions(file_content):\n",
    "    f = StringIO(file_content)\n",
    "    transactions = [line.strip().split() for line in f.readlines()]\n",
    "    return transactions\n",
    "\n",
    "def generate_arff(transactions, output_file_path):\n",
    "    from operator import itemgetter\n",
    "    with open(output_file_path, 'w') as out_file:\n",
    "        # Generate unique item ids and sort them\n",
    "        items = sorted(set(item for transaction in transactions for item in transaction))\n",
    "        item_to_index = {item: index for index, item in enumerate(items)}\n",
    "\n",
    "        # Write ARFF header\n",
    "        out_file.write(\"@relation news_clicks\\n\")\n",
    "        for item in items:\n",
    "            out_file.write(f\"@attribute attr{item} {{0, 1}}\\n\")\n",
    "\n",
    "        # Write ARFF data in sparse format\n",
    "        out_file.write(\"@data\\n\")\n",
    "        for transaction in transactions:\n",
    "            sparse_data = [(item_to_index[item], 1) for item in transaction]\n",
    "            sparse_data = sorted(sparse_data, key=itemgetter(0))\n",
    "            sparse_data_str = \", \".join(f\"{index} {value}\" for index, value in sparse_data)\n",
    "            out_file.write(f\"{{ {sparse_data_str} }}\\n\")\n",
    "\n",
    "    # Return the number of rows (transactions) and columns (unique items)\n",
    "    return len(transactions), len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the input file\n",
    "url = 'http://fimi.uantwerpen.be/data/kosarak.dat' \n",
    "\n",
    "# Download file and generate ARFF\n",
    "file_content = download_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ARFF file has 990002 rows and 41270 columns.\n",
      "The script took 7.3913187980651855 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "transactions = read_transactions(file_content)\n",
    "num_rows, num_cols = generate_arff(transactions, 'kosarak.arff')  # the second argument is the path where you want to save the .arff file\n",
    "\n",
    "print(f\"The ARFF file has {num_rows} rows and {num_cols} columns.\")\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"The script took {execution_time} seconds to run.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am having issues loading  in weka"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
